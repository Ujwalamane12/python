import requests
from bs4 import BeautifulSoup
import sqlite3

# Define a function to create the database and table
def create_db_table():
    conn = sqlite3.connect('books.db')
    c = conn.cursor()

    c.execute('''CREATE TABLE IF NOT EXISTS books 
                (title text, author text, genre text, price real)''')
    conn.commit()

    conn.close()

# Define a function to insert scraped data into the database
def insert_data_into_db(data):
    conn = sqlite3.connect('books.db')
    c = conn.cursor()

    c.execute("INSERT INTO books VALUES (?, ?, ?, ?)", data)
    conn.commit()

    conn.close()

# Define the main function to scrape book data
def scrape_books():
    url = 'http://books.toscrape.com/catalogue/page-{}.html'
    page_num = 1
    all_books_scraped = False

    while not all_books_scraped:
        res = requests.get(url.format(page_num))

        if res.status_code == 200:
            soup = BeautifulSoup(res.content, 'html.parser')

            for book in soup.find_all('article', class_='product_pod'):
                title = book.h3.a['title']
                price = float(book.select('.price_color')[0].get_text()[1:])
                genre = book.select('.genre')[0].get_text().strip()
                author = book.select('.author')[0].get_text().strip()

                # Insert the scraped data into the database
                insert_data_into_db((title, author, genre, price))

            next_page = soup.find_all('li', class_='next')
            if not next_page:
                all_books_scraped = True
            else:
                page_num += 1

# Call the functions to create the database, table and scrape book data
create_db_table()
scrape_books()
